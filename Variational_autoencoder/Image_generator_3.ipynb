{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Input, Flatten,\\\n",
    "Conv2DTranspose, BatchNormalization, LeakyReLU, Reshape, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.express as px"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Das System kann den angegebenen Pfad nicht finden: 'data/Kather_texture_2016_image_tiles_5000'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Look at data folder structure\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m classes_dir \u001B[38;5;241m=\u001B[39m \u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata/Kather_texture_2016_image_tiles_5000\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m classes_dir\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] Das System kann den angegebenen Pfad nicht finden: 'data/Kather_texture_2016_image_tiles_5000'"
     ]
    }
   ],
   "source": [
    "# Look at data folder structure\n",
    "classes_dir = listdir(\"data/Kather_texture_2016_image_tiles_5000\")\n",
    "classes_dir"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# Load data.\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(\"data/Kather_texture_2016_image_tiles_5000\"))\n",
    "data = []\n",
    "labels = []\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "    # extract the class label from the filename\n",
    "    label = (imagePath.split(os.path.sep)[-2][1])\n",
    "    # Since we are going to use MobileNetV2 we need to resize the images\n",
    "    # to the expected size by the pre-trained network.\n",
    "    image = load_img(imagePath, target_size=(32, 32)) # Resize image #image = load_img(imagePath, target_size=(28, 28)) # Resize image\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "    image = tf.cast(image, tf.float32) / 255.0 #normalize\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "# convert the data and labels to NumPy arrays\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# display resized image\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m255\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m#plt.imshow(data[0])\u001B[39;00m\n",
      "\u001B[1;31mIndexError\u001B[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# display resized image\n",
    "plt.imshow(data[0]*255)\n",
    "#plt.imshow(data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # perform one-hot encoding on the labels\n",
    "# lb = LabelBinarizer()\n",
    "# labels = lb.fit_transform(labels)\n",
    "# # labels = to_categorical(labels)\n",
    "# print(labels[0], labels[0][0], type(labels[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split into train, val, test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2,train_size=0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"\\ninput_shape to be used: {input_shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify hyper-parameters-\n",
    "# Images / epochs = batch size\n",
    "batch_size = 192 # 96\n",
    "num_classes = 8\n",
    "num_epochs = 52 #60"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\nDimensions of training and testing sets are:\")\n",
    "print(f\"X_train.shape: {X_train.shape} & X_test.shape: {X_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create TF datasets-\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(4000).batch(batch_size = batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(X_test).shuffle(1000).batch(batch_size = batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize one image\n",
    "img_idx = 499\n",
    "\n",
    "plt.imshow(X_train[img_idx]*255)\n",
    "plt.title(f\"training Image: {img_idx + 1}\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize 20 images-\n",
    "plt.figure(figsize = (15, 10))\n",
    "for i in range(20):\n",
    "    # 4 rows & 5 columns-\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(X_train[i]*255, cmap = plt.get_cmap('gray'))\n",
    "\n",
    "plt.suptitle(\"20 sample images\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Variational Autoencoder network\n",
    "Based on Blog (1) and GitHub (2) of Arjun Majumdar:\n",
    "1. https://medium.com/@arjun.majumdar/variational-autoencoder-cifar-10-tf2-9ed1155771e1\n",
    "2. https://github.com/arjun-majumdar/Autoencoders_Experiments/blob/master/Variational_AutoEncoder_CIFAR10_TF2.ipynb\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ConvBlock(Model):\n",
    "    def __init__(\n",
    "        self, num_filters,\n",
    "        kernel_size, stride_length,\n",
    "        pooling_size, pooling_stride,\n",
    "        padding_type = 'same'\n",
    "    ):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = Conv2D(\n",
    "            filters = num_filters, kernel_size = kernel_size,\n",
    "            strides = stride_length, padding = padding_type,\n",
    "            activation = None, use_bias = False,\n",
    "        )\n",
    "        self.bn = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "\n",
    "        self.conv2 = Conv2D(\n",
    "            filters = num_filters, kernel_size = kernel_size,\n",
    "            strides = stride_length, padding = padding_type,\n",
    "            activation = None, use_bias = False\n",
    "        )\n",
    "        self.bn2 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "\n",
    "        self.pool = MaxPooling2D(\n",
    "            pool_size = pooling_size,\n",
    "            strides = pooling_stride\n",
    "        )\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.keras.activations.relu(self.bn(self.conv1(x)))\n",
    "        x = tf.keras.activations.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Conv6_Encoder(Model):\n",
    "    def __init__(self, latent_dim = 8): #latent_dim = 10\n",
    "        super(Conv6_Encoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.conv_block1 = ConvBlock(\n",
    "            num_filters = 64, kernel_size = 3,\n",
    "            stride_length = 1, pooling_size = 2,\n",
    "            pooling_stride = 2, padding_type = 'valid'\n",
    "            )\n",
    "\n",
    "        self.conv_block2 = ConvBlock(\n",
    "            num_filters = 128, kernel_size = 3,\n",
    "            stride_length = 1, pooling_size = 2,\n",
    "            pooling_stride = 2, padding_type = 'valid'\n",
    "            )\n",
    "\n",
    "        self.conv_block3 = ConvBlock(\n",
    "            num_filters = 256, kernel_size = 3,\n",
    "            stride_length = 1, pooling_size = 2,\n",
    "            pooling_stride = 2, padding_type = 'same'\n",
    "            )\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "        self.output_layer = Dense(\n",
    "            units = self.latent_dim, activation = None\n",
    "            )\n",
    "        self.bn = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = tf.keras.activations.relu(self.bn(self.output_layer(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "    def shape_computation(self, x):\n",
    "        print(f\"Input shape: {x.shape}\")\n",
    "        x = self.conv_block1(x)\n",
    "        print(f\"conv_block1.shape: {x.shape}\")\n",
    "        x = self.conv_block2(x)\n",
    "        print(f\"conv_block2.shape: {x.shape}\")\n",
    "        x = self.conv_block3(x)\n",
    "        print(f\"conv_block3.shape: {x.shape}\")\n",
    "        x = self.flatten(x)\n",
    "        print(f\"flattened shape: {x.shape}\")\n",
    "        x = tf.keras.activations.relu(self.bn(self.output_layer(x)))\n",
    "        print(f\"Encoder output shape: {x.shape}\")\n",
    "        '''\n",
    "        Input shape: (64, 32, 32, 3)\n",
    "        conv_block1.shape: (64, 14, 14, 64)\n",
    "        conv_block2.shape: (64, 5, 5, 128)\n",
    "        conv_block3.shape: (64, 2, 2, 256)\n",
    "        flattened shape: (64, 1024)\n",
    "        Encoder output shape: (64, 100)\n",
    "        '''\n",
    "\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Conv6_Decoder(Model):\n",
    "    def __init__(self, latent_dim = 8): # latent_dim = 10\n",
    "        super(Conv6_Decoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # self.inp_layer = InputLayer(input_shape = self.latent_dim)\n",
    "\n",
    "        self.dense0 = Dense(\n",
    "            units = self.latent_dim, activation = None\n",
    "            )\n",
    "        self.bn0 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "\n",
    "        self.dense = Dense(\n",
    "            units = 1024, #1024\n",
    "            activation = None\n",
    "        )\n",
    "        self.bn = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "\n",
    "        self.dense2 = Dense(\n",
    "            units = 4 * 4 * 256, activation = None\n",
    "        )\n",
    "        self.bn2 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "\n",
    "        self.reshape = Reshape((4, 4, 256))\n",
    "\n",
    "        self.conv_transpose_layer1 = Conv2DTranspose(\n",
    "            filters = 256, kernel_size = 3,\n",
    "            strides = 2, padding = 'same',\n",
    "            activation = None\n",
    "            )\n",
    "        self.bn3 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "\n",
    "        self.conv_transpose_layer2 = Conv2DTranspose(\n",
    "            filters = 256, kernel_size = 3,\n",
    "            strides = 1, padding = 'same',\n",
    "            activation = None\n",
    "            )\n",
    "\n",
    "        self.bn4 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "\n",
    "        self.conv_transpose_layer3 =  Conv2DTranspose(\n",
    "            filters = 128, kernel_size = 3,\n",
    "            strides = 2, padding = 'same',\n",
    "            activation = None\n",
    "            )\n",
    "        self.bn5 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "\n",
    "        self.conv_transpose_layer4 = Conv2DTranspose(\n",
    "            filters = 128, kernel_size = 3,\n",
    "            strides = 1, padding = 'same',\n",
    "            activation = None\n",
    "            )\n",
    "\n",
    "        self.bn6 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "\n",
    "        self.conv_transpose_layer5 = Conv2DTranspose(\n",
    "            filters = 64, kernel_size = 3,\n",
    "            strides = 2, padding = 'same',\n",
    "            activation = None\n",
    "            )\n",
    "        self.bn7 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "\n",
    "        self.conv_transpose_layer6 = Conv2DTranspose(\n",
    "            filters = 64, kernel_size = 3,\n",
    "            strides = 1, padding = 'same',\n",
    "            activation = None\n",
    "            )\n",
    "\n",
    "        self.bn8 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "\n",
    "        self.final_conv_layer = Conv2DTranspose(\n",
    "            filters = 3, kernel_size = 3,\n",
    "            strides = 1, padding = 'same',\n",
    "            activation = None\n",
    "            )\n",
    "\n",
    "\n",
    "    def call(self, X):\n",
    "        # X = self.inp_layer(X)\n",
    "        X = tf.keras.activations.relu(self.bn0(self.dense0(X)))\n",
    "        X = tf.keras.activations.relu(self.bn(self.dense(X)))\n",
    "        X = tf.keras.activations.relu(self.bn2(self.dense2(X)))\n",
    "        X = self.reshape(X)\n",
    "        X = tf.keras.activations.relu(self.bn3(self.conv_transpose_layer1(X)))\n",
    "        X = tf.keras.activations.relu(self.bn4(self.conv_transpose_layer2(X)))\n",
    "        X = tf.keras.activations.relu(self.bn5(self.conv_transpose_layer3(X)))\n",
    "        X = tf.keras.activations.relu(self.bn6(self.conv_transpose_layer4(X)))\n",
    "        X = tf.keras.activations.relu(self.bn7(self.conv_transpose_layer5(X)))\n",
    "        X = tf.keras.activations.relu(self.bn8(self.conv_transpose_layer6(X)))\n",
    "        # X = tf.keras.activations.sigmoid(self.final_conv_layer(X))\n",
    "        X = self.final_conv_layer(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "    def shape_computation(self, x):\n",
    "        print(f\"Input shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn0(self.dense0(x)))\n",
    "        print(f\"first dense layer shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn(self.dense(x)))\n",
    "        print(f\"second dense layer shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn2(self.dense2(x)))\n",
    "        print(f\"third dense layer shape: {x.shape}\")\n",
    "        x = self.reshape(x)\n",
    "        print(f\"reshape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn3(self.conv_transpose_layer1(x)))\n",
    "        print(f\"conv transpose layer1 shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn4(self.conv_transpose_layer2(x)))\n",
    "        print(f\"conv transpose layer2 shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn5(self.conv_transpose_layer3(x)))\n",
    "        print(f\"conv transpose layer3 shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn6(self.conv_transpose_layer4(x)))\n",
    "        print(f\"conv transpose layer4 shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn7(self.conv_transpose_layer5(x)))\n",
    "        print(f\"conv transpose layer5 shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn8(self.conv_transpose_layer6(x)))\n",
    "        print(f\"conv transpose layer6 shape: {x.shape}\")\n",
    "        x = self.final_conv_layer(x)\n",
    "        print(f\"Decoder output shape: {x.shape}\")\n",
    "\n",
    "        '''\n",
    "        Input shape: (64, 100)\n",
    "        first dense layer shape: (64, 100)\n",
    "        second dense layer shape: (64, 1024)\n",
    "        third dense layer shape: (64, 4096)\n",
    "        reshape: (64, 4, 4, 256)\n",
    "        conv transpose layer1 shape: (64, 8, 8, 256)\n",
    "        conv transpose layer2 shape: (64, 8, 8, 256)\n",
    "        conv transpose layer3 shape: (64, 16, 16, 128)\n",
    "        conv transpose layer4 shape: (64, 16, 16, 128)\n",
    "        conv transpose layer5 shape: (64, 32, 32, 64)\n",
    "        conv transpose layer6 shape: (64, 32, 32, 64)\n",
    "        Decoder output shape: (64, 32, 32, 3)\n",
    "        '''\n",
    "\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sanity Checks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder = Conv6_Encoder(latent_dim = 100)\n",
    "decoder = Conv6_Decoder(latent_dim = 100)\n",
    "x = next(iter(train_dataset))\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_enc = encoder(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_recon = decoder(x_enc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_enc.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x.shape, x_recon.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder.shape_computation(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decoder.shape_computation(x_enc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# del encoder, decoder, x, x_enc, x_recon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the VAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Sampling(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Create a sampling layer.\n",
    "    Uses (mu, log_var) to sample latent vector 'z'.\n",
    "    \"\"\"\n",
    "    def call(self, mu, log_var):\n",
    "    # def call(self, inputs):\n",
    "        # z_mean, z_log_var = inputs\n",
    "\n",
    "        # Get batch size-\n",
    "        batch = tf.shape(mu)[0]\n",
    "\n",
    "        # Get latent space dimensionality-\n",
    "        dim = tf.shape(mu)[1]\n",
    "\n",
    "        # Add stochasticity by sampling from a multivariate standard\n",
    "        # Gaussian distribution-\n",
    "        epsilon = tf.keras.backend.random_normal(\n",
    "            shape = (batch, dim), mean = 0.0,\n",
    "            stddev = 1.0\n",
    "        )\n",
    "\n",
    "        return mu + (tf.exp(0.5 * log_var) * epsilon)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, latent_space = 100):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.latent_space = latent_space\n",
    "\n",
    "        self.encoder = Conv6_Encoder(latent_dim = self.latent_space)\n",
    "        self.decoder = Conv6_Decoder(latent_dim = self.latent_space)\n",
    "\n",
    "        # Define fully-connected layers for computing mean & log variance-\n",
    "        self.mu = Dense(units = self.latent_space, activation = None)\n",
    "        self.log_var = Dense(units = self.latent_space, activation = None)\n",
    "\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # Sample from a multivariate Gaussian distribution.\n",
    "        # Adds stochasticity or variation-\n",
    "        eps = tf.random.normal(\n",
    "            shape = mu.shape, mean = 0.0,\n",
    "            stddev = 1.0\n",
    "        )\n",
    "        return (eps * tf.exp(logvar * 0.5) + mu)\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        # print(f\"x.shape: {x.shape}\")\n",
    "        # x.shape: (batch_size, 100)\n",
    "\n",
    "        mu = self.mu(x)\n",
    "        log_var = self.log_var(x)\n",
    "        # z = self.reparameterize(mu, log_var)\n",
    "        # z = Sampling()([mu, log_var])\n",
    "        z = Sampling()(mu, log_var)\n",
    "        '''\n",
    "        print(f\"mu.shape: {mu.shape}, log_var.shape: {log_var.shape}\"\n",
    "              f\" & z.shape: {z.shape}\")\n",
    "        # mu.shape: (batch_size, 100), log_var.shape: (batch_size, 100) & z.shape: (batch_size, 100)\n",
    "        '''\n",
    "\n",
    "        x = tf.keras.activations.sigmoid(self.decoder(z))\n",
    "        return x, mu, log_var\n",
    "\n",
    "\n",
    "    def model(self):\n",
    "        '''\n",
    "        Overrides 'model()' call.\n",
    "        Output shape is not well-defined when using sub-classing. As a\n",
    "        workaround, this method is implemeted.\n",
    "        '''\n",
    "        x = Input(shape = (32, 32, 3))\n",
    "        return Model(inputs = [x], outputs = self.call(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize VAE model-\n",
    "model = VAE(latent_space = 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sanity check-\n",
    "x = next(iter(train_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Forward pass using input data-\n",
    "x_recon, mu, log_var = model(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x.shape, x_recon.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mu.shape, log_var.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mu.numpy().mean(), mu.numpy().std()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_var.numpy().mean(), log_var.numpy().std()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# del x, x_recon, mu, log_var"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get model summary-\n",
    "model.model().summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Count layer-wise number of trainable parameters-\n",
    "tot_params = 0\n",
    "\n",
    "for layer in model.trainable_weights:\n",
    "    loc_params = tf.math.count_nonzero(layer, axis = None).numpy()\n",
    "    tot_params += loc_params\n",
    "    print(f\"layer: {layer.shape} has {loc_params} parameters\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"VAE has {tot_params} trainable parameters\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define an optimizer-\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001) #1e-4 (0.0001) # 0.000001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train VAE CNN based model using tf.GradientTape()\n",
    "def compute_loss(data, reconstruction, mu, log_var, alpha = 1): # alpha = 1\n",
    "\n",
    "    # Reconstruction loss-\n",
    "    # recon_loss = tf.keras.losses.mean_squared_error(K.flatten(data), K.flatten(reconstruction))\n",
    "\n",
    "    recon_loss = tf.reduce_mean(\n",
    "        tf.reduce_sum(\n",
    "            # tf.keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "            tf.keras.losses.mean_squared_error(data, reconstruction),\n",
    "            axis = (1, 2)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # KL-divergence loss-\n",
    "    kl_loss = -0.5 * (1 + log_var - tf.square(mu) - tf.exp(log_var))\n",
    "    kl_loss = tf.reduce_mean(\n",
    "        tf.reduce_sum(\n",
    "            kl_loss,\n",
    "            axis = 1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    total_loss = (recon_loss * alpha) + kl_loss\n",
    "\n",
    "    return total_loss, recon_loss, kl_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_one_step(model, optimizer, data, alpha):\n",
    "    # Function to perform one step/iteration of training\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Make predictions using defined model-\n",
    "        data_recon, mu, log_var = model(data)\n",
    "\n",
    "        # Compute loss-\n",
    "        total_loss, recon_loss, kl_loss = compute_loss(\n",
    "            data = data, reconstruction = data_recon,\n",
    "            mu = mu, log_var = log_var,\n",
    "            alpha = alpha\n",
    "        )\n",
    "\n",
    "    # Compute gradients wrt defined loss and weights and biases-\n",
    "    grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "\n",
    "    # type(grads)\n",
    "    # list\n",
    "\n",
    "    # Apply computed gradients to model's weights and biases-\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    return total_loss, recon_loss, kl_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(model, optimizer, data, alpha):\n",
    "    '''\n",
    "    Function to test model performance\n",
    "    on testing dataset\n",
    "    '''\n",
    "    # Make predictions using defined model-\n",
    "    data_recon, mu, log_var = model(data)\n",
    "\n",
    "    # Compute loss-\n",
    "    total_loss, recon_loss, kl_loss = compute_loss(\n",
    "        data = data, reconstruction = data_recon,\n",
    "        mu = mu, log_var = log_var,\n",
    "        alpha = alpha\n",
    "    )\n",
    "\n",
    "    return total_loss, recon_loss, kl_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(f\"Train VAE model for {num_epochs} epochs\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Python3 dict to contain training metrics-\n",
    "training_metrics = {}\n",
    "val_metrics = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify hyper-parameter for reconstruction loss vs. kl-divergence-\n",
    "alpha = 10 #10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    \"\"\"\n",
    "    # Manual early stopping implementation-\n",
    "    if loc_patience >= patience:\n",
    "        print(\"\\n'EarlyStopping' called!\\n\")\n",
    "        break\n",
    "    \"\"\"\n",
    "\n",
    "    # Epoch train & validation losses-\n",
    "    train_loss = 0.0\n",
    "    train_r_loss = 0.0\n",
    "    train_kl_l = 0.0\n",
    "    val_loss = 0.0\n",
    "    val_r_loss = 0.0\n",
    "    val_kl_l = 0.0\n",
    "\n",
    "    for data in train_dataset:\n",
    "        train_total_loss, train_recon_loss, train_kl_loss = train_one_step(\n",
    "            model = model, optimizer = optimizer,\n",
    "            data = data, alpha = alpha\n",
    "        )\n",
    "\n",
    "        train_loss += train_total_loss.numpy()\n",
    "        train_r_loss += train_recon_loss.numpy()\n",
    "        train_kl_l += train_kl_loss.numpy()\n",
    "\n",
    "    for test_data in test_dataset:\n",
    "        test_total_loss, test_recon_loss, test_kl_loss = test_step(\n",
    "            model = model, optimizer = optimizer,\n",
    "            data = test_data, alpha = alpha)\n",
    "\n",
    "        val_loss += test_total_loss.numpy()\n",
    "        val_r_loss += test_recon_loss.numpy()\n",
    "        val_kl_l += test_kl_loss.numpy()\n",
    "\n",
    "    # vae_train_loss.append(train_loss)\n",
    "    # vae_val_loss.append(val_loss)\n",
    "\n",
    "    training_metrics[epoch] = {\n",
    "        'total_loss': train_loss, 'recon_loss': train_r_loss,\n",
    "        'kl_loss': train_kl_l\n",
    "        }\n",
    "\n",
    "    val_metrics[epoch] = {\n",
    "        'total_loss': val_loss, 'recon_loss': val_r_loss,\n",
    "        'kl_loss': val_kl_l\n",
    "    }\n",
    "\n",
    "    print(f\"epoch = {epoch}; total train loss = {train_loss:.4f},\"\n",
    "    f\" train recon loss = {train_r_loss:.4f}, train kl loss = {train_kl_l:.4f};\"\n",
    "    f\" total val loss = {val_loss:.4f}, val recon loss = {val_r_loss:.4f} &\"\n",
    "    f\" val kl loss = {val_kl_l:.4f}\"\n",
    "    )\n",
    "\n",
    "    '''\n",
    "    # Save 'best' model so far-\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        print(f\"Saving VAE model with val_los = {val_loss:.4f}\")\n",
    "        model.save_weights(\"VAE_tissue_best_model.h5\", overwrite = True)\n",
    "    '''\n",
    "\n",
    "    \"\"\"\n",
    "    # Code for manual Early Stopping:\n",
    "    #if np.abs(val_loss < best_val_loss) >= minimum_delta:\n",
    "    if (val_loss < best_val_loss) and \\\n",
    "    (np.abs(val_loss - best_val_loss) >= minimum_delta):\n",
    "\n",
    "        # update 'best_val_loss' variable to lowest loss encountered so far-\n",
    "        best_val_loss = val_loss\n",
    "\n",
    "        # reset 'loc_patience' variable-\n",
    "        loc_patience = 0\n",
    "\n",
    "        print(f\"Saving model with lowest val_loss = {val_loss:.4f}\\n\")\n",
    "\n",
    "        # Save trained model with 'best' validation accuracy-\n",
    "        model.save_weights(\"VAE_tissue_best_model.h5\", overwrite = True)\n",
    "\n",
    "    else:  # there is no improvement in monitored metric 'val_loss'\n",
    "        loc_patience += 1  # number of epochs without any improvement\n",
    "    \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sanity check for Python3 dicts containing training metrics-\n",
    "training_metrics.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_metrics.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_metrics[5].keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_metrics[5].keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save trained model at the end of training-\n",
    "model.save_weights(\"VAE_tissue_last_epoch.h5\", overwrite = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize training metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize = (9, 7))\n",
    "plt.plot([training_metrics[e]['total_loss'] for e in training_metrics.keys()], label = 'train total loss')\n",
    "plt.legend(loc = 'best')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.title(\"VAE: Training Visualization - Total Training Loss\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize = (9, 7))\n",
    "plt.plot([training_metrics[e]['recon_loss'] for e in training_metrics.keys()], label = 'train recon loss')\n",
    "plt.legend(loc = 'best')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.title(\"VAE: Training Visualization - Reconstruction Loss (training)\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize = (9, 7))\n",
    "plt.plot([val_metrics[e]['recon_loss'] for e in val_metrics.keys()], label = 'val recon loss')\n",
    "plt.legend(loc = 'best')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.title(\"VAE: Training Visualization - Reconstruction Loss (validation)\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualise reconstructed images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get reconstructions, mean & log-variance from trained model-\n",
    "X_train_reconstruced, mu, log_var = model(X_train[:1000, :])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize one of reconstructed images-\n",
    "img_idx = 200\n",
    "\n",
    "plt.imshow(X_train_reconstruced[img_idx]*255) # *255 added\n",
    "plt.title(f\"Reconstructed Image: {img_idx + 1}\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sanity check-\n",
    "X_train[:1000, :].shape, X_train_reconstruced.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize 20 reconstruced images-\n",
    "plt.figure(figsize = (9, 7))\n",
    "for i in range(20):\n",
    "    # 4 rows & 5 columns-\n",
    "    plt.subplot(4, 5, i + 1) # 4 / 5\n",
    "    plt.imshow(X_train_reconstruced[i]*255) # *255 added\n",
    "\n",
    "plt.suptitle(\"Reconstructed images\")\n",
    "plt.savefig('VAE_Reconstructed_Images2.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}